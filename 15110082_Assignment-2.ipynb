{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment-2 of Pansetty Karthik (15110082)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from urllib import request\n",
    "import random\n",
    "import re\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "import math\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question 1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 1\"\"\"\n",
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/cache/epub/1661/pg1661.txt\"\n",
    "\n",
    "sherlock = request.urlopen(url)\n",
    "sherlock_text = sherlock.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question 2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Text preprocessing by removing line breaks and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherlock_text = re.sub('\\n', ' ', sherlock_text)\n",
    "sherlock_text = re.sub('\\r', ' ', sherlock_text)\n",
    "sherlock_text = re.sub('\\ufeff', '', sherlock_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = []\n",
    "for text in sherlock_text:\n",
    "    punctuations = '''()-[]{};:\"<>/?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in text:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    processed_text.append(no_punct)\n",
    "    \n",
    "result= ''\n",
    "for element in processed_text:\n",
    "    result += str(element)\n",
    "    \n",
    "sherlock_text = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6198"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences_list = sent_tokenize(sherlock_text)\n",
    "len(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/k/kpansett/anaconda3/envs/py36-test/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_sent, test_sent = train_test_split(sentences_list,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding <s> for start of sentence and </s> for end of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in train_sent:\n",
    "    tokens = word_tokenize(i)\n",
    "    train_data.append('<s>')\n",
    "    train_data = train_data + tokens\n",
    "    train_data.append('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in test_sent:\n",
    "    tokens = word_tokenize(i)\n",
    "    test_data.append('<s>')\n",
    "    test_data = test_data + tokens\n",
    "    test_data.append('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question 3'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 3\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unigram(tokens):\n",
    "    unigrams = ngrams(tokens, 1)\n",
    "    unigram_list =tokens\n",
    "    unigram_count_dict = dict(Counter(unigram_list))\n",
    "    \n",
    "    unigram_probability = {}\n",
    "    for j in range(len(unigram_list)):\n",
    "        unigram_probability[unigram_list[j]]  = unigram_count_dict[unigram_list[j]]/len(unigram_list)\n",
    "    \n",
    "    return unigram_list,unigram_count_dict,unigram_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Unigrams\"\"\"\n",
    "unigram_list,unigram_count_dict,unigram_probability = Unigram(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(unigram_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For n>1\n",
    "\n",
    "def nGram(tokens,n):\n",
    "    nGrams = ngrams(tokens, n)\n",
    "    ngram_list =(list(nGrams))\n",
    "    ngram_count_dict = dict(Counter(ngram_list))\n",
    "    \n",
    "    tGrams = ngrams(tokens, n-1)\n",
    "    tgram_list =(list(tGrams))\n",
    "    tgram_count_dict = dict(Counter(tgram_list))\n",
    "    \n",
    "    ngrams1 = list(ngram_count_dict.keys())\n",
    "    ngram_probability={}\n",
    "    ngram_probability_smoothing={}\n",
    "\n",
    "    for j in range(len(ngrams1)):\n",
    "        words = (ngrams1[j][0:n-1])\n",
    "        ngram_probability[ngrams1[j]]  = ngram_count_dict[ngrams1[j]]/tgram_count_dict[words]\n",
    "        ngram_probability_smoothing[ngrams1[j]]  = (ngram_count_dict[ngrams1[j]]+1)/(tgram_count_dict[words]+vocab_size)\n",
    "    \n",
    "    return ngram_list, ngram_count_dict, ngram_probability, ngram_probability_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bigrams\"\"\"\n",
    "bigram_list, bigram_count_dict, bigram_probability, bigram_probability_smoothing = nGram(tokens,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trigrams\"\"\"\n",
    "trigram_list, trigram_count_dict, trigram_probability, _ = nGram(tokens,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Quadgrams\"\"\"\n",
    "quadgram_list, quadgram_count_dict, quadgram_probability, _ = nGram(tokens,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find number of nGrams possible\n",
    "# Number of nGrams is nCr as the vocab consists of n words and we need r words in an r-gram \n",
    "# Number of Combinations = nCr\n",
    "\n",
    "def ncr(n,r):\n",
    "    ncr = math.factorial(n)/(math.factorial(n-r)*math.factorial(r))\n",
    "    return int(ncr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  8518\n",
      "\n",
      "no. of unigrams present:  8518\n",
      "no. of unigrams possible:  8518\n",
      "\n",
      "no. of bigrams present:  44134\n",
      "no. of bigrams possible:  36273903\n",
      "\n",
      "no. of trigrams present:  77204\n",
      "no. of trigrams possible:  102969519316\n",
      "\n",
      "no. of quadgrams present:  92316\n",
      "no. of quadgrams possible:  219196364243935\n"
     ]
    }
   ],
   "source": [
    "print('Vocab Size: ', vocab_size)\n",
    "print()\n",
    "print('no. of unigrams present: ', vocab_size)\n",
    "print('no. of unigrams possible: ', vocab_size)\n",
    "print()\n",
    "print('no. of bigrams present: ', len(bigram_count_dict))\n",
    "print('no. of bigrams possible: ', ncr(vocab_size,2))\n",
    "print()\n",
    "print('no. of trigrams present: ', len(trigram_count_dict))\n",
    "print('no. of trigrams possible: ', ncr(vocab_size,3))\n",
    "print()\n",
    "print('no. of quadgrams present: ', len(quadgram_count_dict))\n",
    "print('no. of quadgrams possible: ', ncr(vocab_size,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question 4'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 4\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(model_name):\n",
    "    \n",
    "    sentence=[]\n",
    "    first_word = \"<s>\"\n",
    "    sentence.append(first_word)\n",
    "    max_length = 20\n",
    "    \n",
    "    if model_name == 'unigram':\n",
    "        model = unigram_probability\n",
    "        model_sorted=list(model.keys())\n",
    "        current = sentence[0]\n",
    "       \n",
    "        while current != '</s>' and len(sentence)<max_length:\n",
    "            random_word = random.choice(model_sorted)\n",
    "            sentence.append(random_word)\n",
    "            current = random_word\n",
    "        \n",
    "        complete_sentence = ' '.join(sentence)\n",
    "        return complete_sentence \n",
    "        \n",
    "    elif model_name == 'bigram':\n",
    "        model = bigram_probability\n",
    "        model_sorted=list(model.keys())\n",
    "        current = sentence[0]\n",
    "\n",
    "        \n",
    "        while current != '</s>' and len(sentence)<max_length:\n",
    "            if current == \"<s>\" and len(sentence)<2:\n",
    "                random_word = random.choice(list(unigram_probability.keys()))\n",
    "                sentence.append(random_word)\n",
    "                current = random_word\n",
    "            else:\n",
    "                tmp_key=[]\n",
    "                tmp_val=[]\n",
    "                for i in range(len(model_sorted)):\n",
    "                    if model_sorted[i][0] == current:\n",
    "                        tmp_key.append(model_sorted[i][1])\n",
    "                        tmp_val.append(model[model_sorted[i]])\n",
    "\n",
    "                index, value = max(enumerate(tmp_val), key=op.itemgetter(1))\n",
    "                next_word = tmp_key[index]\n",
    "                sentence.append(next_word)\n",
    "                current = next_word\n",
    "            \n",
    "        complete_sentence = ' '.join(sentence)\n",
    "        return complete_sentence \n",
    "    \n",
    "    \n",
    "    elif model_name == 'trigram':\n",
    "        model = trigram_probability\n",
    "        model_sorted=list(model.keys())\n",
    "        current = sentence[0]\n",
    "\n",
    "        \n",
    "        while current != '</s>' and len(sentence)<max_length:\n",
    "            if current == \"<s>\" and len(sentence)<3:\n",
    "                random_word = random.choice(list(bigram_probability.keys()))\n",
    "                sentence.append(random_word[0])\n",
    "                sentence.append(random_word[1])\n",
    "                current = random_word[1]\n",
    "            else:\n",
    "                tmp_key=[]\n",
    "                tmp_val=[]\n",
    "                for i in range(len(model_sorted)):\n",
    "                    if model_sorted[i][0] == sentence[-2] and model_sorted[i][1] == sentence[-1]:\n",
    "                        tmp_key.append(model_sorted[i][2])\n",
    "                        tmp_val.append(model[model_sorted[i]])\n",
    "\n",
    "                index, value = max(enumerate(tmp_val), key=op.itemgetter(1))\n",
    "                next_word = tmp_key[index]\n",
    "                sentence.append(next_word)\n",
    "                current = next_word\n",
    "            \n",
    "        complete_sentence = ' '.join(sentence)\n",
    "        return complete_sentence  \n",
    "    \n",
    "    elif model_name == 'quadgram':\n",
    "        model = quadgram_probability\n",
    "        model_sorted=list(model.keys())\n",
    "        current = sentence[0]\n",
    "\n",
    "        \n",
    "        while current != '</s>' and len(sentence)<max_length:\n",
    "            if current == \"<s>\" and len(sentence)<4:\n",
    "                random_word = random.choice(list(trigram_probability.keys()))\n",
    "                sentence.append(random_word[0])\n",
    "                sentence.append(random_word[1])\n",
    "                sentence.append(random_word[2])\n",
    "                current = random_word[2]\n",
    "            else:\n",
    "                tmp_key=[]\n",
    "                tmp_val=[]\n",
    "                for i in range(len(model_sorted)):\n",
    "                    if model_sorted[i][0] == sentence[-3] and model_sorted[i][1] == sentence[-2] and model_sorted[i][2] == sentence[-1]:\n",
    "                        tmp_key.append(model_sorted[i][3])\n",
    "                        tmp_val.append(model[model_sorted[i]])\n",
    "\n",
    "                index, value = max(enumerate(tmp_val), key=op.itemgetter(1))\n",
    "                next_word = tmp_key[index]\n",
    "                sentence.append(next_word)\n",
    "                current = next_word\n",
    "            \n",
    "        complete_sentence = ' '.join(sentence)\n",
    "        return complete_sentence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> shone plugs lodginghouse glance severely regret anxiously outrages point lenses encamp common prices passage shading ha purchasing partly Arms'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator('unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> wellopened eye . </s>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator('bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> blue stone of the house , and I have no doubt that the doctor 's advice and help ,\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator('trigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> will have informed the police of Savannah that these three gentlemen are badly wanted here upon a charge of'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator('quadgram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 \n",
    "# -\n",
    "# 2\n",
    "# log_probability = unigram_probability[sentence_tokens[0]]\n",
    "# 3\n",
    "# log_probability = unigram_probability[sentence_tokens[0]] + bigram_probability[(sentence_tokens[0],sentence_tokens[1])]\n",
    "# 4\n",
    "# log_probability = unigram_probability[sentence_tokens[0]] + bigram_probability[(sentence_tokens[0],sentence_tokens[1])] + trigram_probability[(sentence_tokens[0],sentence_tokens[1], sentence_tokens[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Probability(sentence,model_name):\n",
    "    \n",
    "    log_probability = 0\n",
    "    sentence_tokens = sentence.split()\n",
    "    \n",
    "    if model_name == 'unigram':\n",
    "        for i in range(len(sentence_tokens)):\n",
    "            log_probability = log_probability + math.log2(unigram_probability[sentence_tokens[i]])\n",
    "    \n",
    "    elif model_name == 'bigram':\n",
    "        for i in range(1,len(sentence_tokens)):\n",
    "            log_probability = log_probability + math.log2(bigram_probability[(sentence_tokens[i-1],sentence_tokens[i])])\n",
    "            \n",
    "    elif model_name == 'trigram':\n",
    "        for i in range(2,len(sentence_tokens)):\n",
    "            log_probability = log_probability + math.log2(trigram_probability[(sentence_tokens[i-2],sentence_tokens[i-1],sentence_tokens[i])])\n",
    "    \n",
    "    elif model_name == 'quadgram':\n",
    "        for i in range(3,len(sentence_tokens)):\n",
    "            log_probability = log_probability + math.log2(quadgram_probability[(sentence_tokens[i-3],sentence_tokens[i-2],sentence_tokens[i-1],sentence_tokens[i])])\n",
    "    \n",
    "    return log_probability\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-45.53640820473585"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Probability('blue stone of the house','unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16.963722837938732"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Probability('blue stone of the house','bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question 5'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 5\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing first ten probabilities of bigrams and add-1 smoothed bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>', 'The'), 0.018477292965271595),\n",
       " (('The', 'inspector'), 0.00034110289937464467),\n",
       " (('inspector', 'and'), 0.0005858917272088118),\n",
       " (('and', 'two'), 0.0009271277582050807),\n",
       " (('two', 'men'), 0.0005791729410401946),\n",
       " (('men', 'accompanied'), 0.0002338907730090048),\n",
       " (('accompanied', 'her'), 0.00023476933912431035),\n",
       " (('her', 'back'), 0.0003391746749576032),\n",
       " (('back', ','), 0.001159151501101194),\n",
       " ((',', 'and'), 0.0743481803367735)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10,bigram_probability_smoothing.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>', 'The'), 0.0500201694231545),\n",
       " (('The', 'inspector'), 0.007220216606498195),\n",
       " (('inspector', 'and'), 0.25),\n",
       " (('and', 'two'), 0.003968253968253968),\n",
       " (('two', 'men'), 0.034782608695652174),\n",
       " (('men', 'accompanied'), 0.030303030303030304),\n",
       " (('accompanied', 'her'), 1.0),\n",
       " (('her', 'back'), 0.0061162079510703364),\n",
       " (('back', ','), 0.08256880733944955),\n",
       " ((',', 'and'), 0.17616747181964573)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, bigram_probability.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If we observe in the above values ('inspector', 'and') and ('accompanied', 'her') have drastic change in probabilities. We see this because there is a change of count in the bigrams when we add smoothing. For example if there is a bigram occuring only one time (whose both words also occur only in this bigram), its probability will be decreased drastically when we smoothen it\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"If we observe in the above values ('inspector', 'and') and ('accompanied', 'her') have drastic change in probabilities. We see this because there is a change of count in the bigrams when we add smoothing. For example if there is a bigram occuring only one time (whose both words also occur only in this bigram), its probability will be decreased drastically when we smoothen it\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question 6'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 6\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoodTuring(bigram_count_dict):\n",
    "    b = bigram_count_dict.values()\n",
    "\n",
    "    frequencies = {}\n",
    "\n",
    "    for i in b:\n",
    "        if i not in frequencies:\n",
    "            frequencies[i] = 1\n",
    "        else:\n",
    "            frequencies[i]+=1\n",
    "\n",
    "    c_star = {}\n",
    "    for i in range(1,10):\n",
    "        c_star[i] = ((i+1)*frequencies[i+1])/frequencies[i]\n",
    "\n",
    "    return c_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_turing = GoodTuring(bigram_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.3225201801856275,\n",
       " 2: 1.109111361079865,\n",
       " 3: 2.026369168356998,\n",
       " 4: 2.932932932932933,\n",
       " 5: 3.7781569965870307,\n",
       " 6: 5.1409214092140925,\n",
       " 7: 6.878228782287823,\n",
       " 8: 6.334763948497854,\n",
       " 9: 9.329268292682928}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_val = {}\n",
    "\n",
    "for key, val in good_turing.items():\n",
    "    d_val[key] = key-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.6774798198143726,\n",
       " 2: 0.8908886389201349,\n",
       " 3: 0.973630831643002,\n",
       " 4: 1.0670670670670672,\n",
       " 5: 1.2218430034129693,\n",
       " 6: 0.8590785907859075,\n",
       " 7: 0.12177121771217703,\n",
       " 8: 1.6652360515021458,\n",
       " 9: -0.32926829268292757}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_val_obtained = sum(list(d_val.values()))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4295453856349698"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_val_obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_turing_prob = bigram_probability\n",
    "\n",
    "for key in bigram_count_dict:\n",
    "    if bigram_count_dict[key] in good_turing:\n",
    "        good_turing_prob[key] = good_turing[bigram_count_dict[key]]/unigram_count_dict[key[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question 7'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 7\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_list_test = list(ngrams(test_data,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Perplexity for Add-One Smoothing and Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_perplexity(bigram_list_test, bigram_probability):\n",
    "    \n",
    "    prod_bigrams = 1\n",
    "    for i in bigram_list_test:\n",
    "        if i in bigram_probability:\n",
    "            prod_bigrams = prod_bigrams*(np.power(1/bigram_probability[i],1/num))\n",
    "    \n",
    "        else:\n",
    "            prod_bigrams = prod_bigrams*(np.power(vocab_size,1/num))\n",
    "    perplexity = (prod_bigrams)\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_add1 = bigram_perplexity(bigram_list_test,bigram_probability_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_good_turing = bigram_perplexity(bigram_list_test, good_turing_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863.5598688263821"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_add1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.66786744662392"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_good_turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
